import argparse, json, os, time
from typing import List, Dict
from .dataset import load_jsonl, safe_open_image
from .metrics import center_in_box, summarize
from baselines.screenspot_pro import region_search, text_rule

def _save_calibration_png(examples:List[Dict], out_path:str):
    try:
        import matplotlib.pyplot as plt
    except Exception:
        return
    totals = [0]*10; correct=[0]*10
    for ex in examples:
        c = max(0.0, min(0.999, float(ex.get("confidence",0.0))))
        b = int(c*10)
        totals[b]+=1
        if ex.get("success"): correct[b]+=1
    xs=[]; ys=[]
    for i in range(10):
        if totals[i]==0: continue
        xs.append((i+0.5)/10.0)
        ys.append(correct[i]/totals[i])
    plt.figure()
    plt.plot(xs, ys, marker="o", label="model")
    plt.plot([0,1],[0,1], linestyle="--", label="ideal")
    plt.xlabel("confidence"); plt.ylabel("accuracy"); plt.legend()
    plt.title("Calibration")
    plt.savefig(out_path, bbox_inches="tight"); plt.close()

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--annotations", required=True)
    ap.add_argument("--root", default=".")
    ap.add_argument("--subset", type=int, default=0)
    ap.add_argument("--max_resolution", type=int, default=None)
    ap.add_argument("--per_example_file", default=None)
    ap.add_argument("--calibration_png", default=None)
    ap.add_argument("--baseline", choices=["region","text"], default="region")
    args = ap.parse_args()

    records = load_jsonl(args.annotations)
    if args.subset and args.subset < len(records):
        records = records[:args.subset]

    per = []
    skipped = []
    t0 = time.time()
    for r in records:
        img_path = os.path.join(args.root, "data", "mock_screenspot_pro", r["image_path"]) \
                   if not os.path.isabs(r["image_path"]) else r["image_path"]

        im, err, scale = safe_open_image(img_path, args.max_resolution)
        if err:
            skipped.append({"path": img_path, "reason": err})
            continue

        # Scale gold box if we resized
        gx0, gy0, gx1, gy1 = r["bbox"]
        gold = [int(gx0*scale), int(gy0*scale), int(gx1*scale), int(gy1*scale)] if scale != 1.0 else r["bbox"]

        priors = os.path.join(args.root, "baselines", "screenspot_pro", "priors.json")
        if args.baseline == "region":
            box = region_search.predict_box(im, r["instruction"], priors)
            conf = region_search.predict_confidence(im, r["instruction"], priors)
        else:
            box = text_rule.predict_box(im, r["instruction"], priors)
            conf = text_rule.predict_confidence(im, r["instruction"], priors)

        W, H = im.size
        success = center_in_box(box, gold, W, H)
        per.append({
            "image_path": img_path,
            "instruction": r["instruction"],
            "pred_box": box,
            "gold_box": gold,
            "target_type": r["target_type"],
            "W": W, "H": H,
            "success": success,
            "confidence": float(conf),
            "scale": scale,
        })

    wall = time.time()-t0
    summary = summarize(per)
    if per:
        summary["avg_inference_time_ms"] = 1000.0*wall/len(per)
    summary["wall_time_s"] = wall
    summary["evaluated_count"] = len(per)
    summary["skipped_count"] = len(skipped)
    if skipped:
        summary["skipped_paths"] = skipped

    print(json.dumps(summary, indent=2))
    if args.per_example_file:
        with open(args.per_example_file,"w",encoding="utf-8") as f:
            json.dump(per, f, indent=2)
    if args.calibration_png and per:
        _save_calibration_png(per, args.calibration_png)

if __name__ == "__main__":
    main()
